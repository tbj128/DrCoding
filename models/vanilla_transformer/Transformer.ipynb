{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Commands\n",
    "\n",
    "### TOY\n",
    "#### Train \n",
    "python run.py train --train-src=../data_toy/train.data --dev-src=../data_toy/test.data --vocab=vocab.toy.json --glove-path=../embeddings/glove.6B.100d.txt --target-length=10 --valid-niter=2 --model=transformer --transformer-depth=2 --transformer-heads=8 --log-every=1 --save-to=model.transformer.bin\n",
    "epoch 4, iter 13, avg. loss 0.88 total examples 32, speed 3082.23 words/sec, time elapsed 0.99 sec\n",
    "epoch 4, iter 14, avg. loss 0.83 total examples 32, speed 4798.25 words/sec, time elapsed 1.05 sec\n",
    "VALIDATION: 14 | Precision 1.0, recall 1.0, f1 1.0, accuracy: 1.0\n",
    "save currently the best model to [model.transformer.bin]\n",
    "save model parameters to [model.transformer.bin]\n",
    "\n",
    "\n",
    "#### Test \n",
    "python run.py predict model.transformer.bin ../data_toy/test.data ../predictions/transformer.txt --target-length=10  --model=transformer --log-every=1\n",
    "load test source sentences from [../data_toy/test.data]\n",
    "load model from model.transformer.bin\n",
    "Using device: cpu\n",
    "Precision 1.0, recall 1.0, f1 1.0, accuracy: 1.0\n",
    "\n",
    "\n",
    "\n",
    "### FULL\n",
    "#### Train \n",
    "\n",
    "Note: larger batch sizes will lead to out of memory on the GPU\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=1024 --batch-size=10 --valid-niter=100 --model=transformer --transformer-depth=1 --transformer-heads=8 --save-to=model.transformer.bin --cuda &\n",
    "\n",
    "[nohup.out.transformer]\n",
    "epoch 1, iter 3110, avg. loss 15.13 total examples 100, speed 2030.37 words/sec, time elapsed 1884.87 sec\n",
    "epoch 1, iter 3120, avg. loss 14.92 total examples 100, speed 88004.90 words/sec, time elapsed 1886.04 sec\n",
    "epoch 1, iter 3130, avg. loss 13.43 total examples 100, speed 87899.55 words/sec, time elapsed 1887.20 sec\n",
    "epoch 1, iter 3140, avg. loss 13.98 total examples 100, speed 87621.62 words/sec, time elapsed 1888.37 sec\n",
    "epoch 1, iter 3150, avg. loss 15.22 total examples 100, speed 87650.57 words/sec, time elapsed 1889.54 sec\n",
    "epoch 1, iter 3160, avg. loss 15.35 total examples 100, speed 87896.76 words/sec, time elapsed 1890.70 sec\n",
    "epoch 1, iter 3170, avg. loss 14.17 total examples 100, speed 87868.30 words/sec, time elapsed 1891.87 sec\n",
    "epoch 1, iter 3180, avg. loss 14.17 total examples 100, speed 87828.21 words/sec, time elapsed 1893.04 sec\n",
    "epoch 1, iter 3190, avg. loss 15.46 total examples 100, speed 87828.62 words/sec, time elapsed 1894.20 sec\n",
    "epoch 1, iter 3200, avg. loss 14.44 total examples 100, speed 87813.22 words/sec, time elapsed 1895.37 sec\n",
    "VALIDATION: 3200 | Precision 0.2873416179337232, recall 0.06906754041788794, f1 0.10370291829179984, accuracy: 0.8855750487329135\n",
    "save currently the best model to [model.transformer.bin]\n",
    "save model parameters to [model.transformer.bin]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=1024 --batch-size=10 --valid-niter=100 --model=transformer --save-to=model.transformer.2.bin --transformer-depth=4 --transformer-heads=2 --cuda &\n",
    "\n",
    "[nohup.out.transformer.2]\n",
    "epoch 1, iter 2510, avg. loss 17.02 total examples 100, speed 1225.43 words/sec, time elapsed 2561.81 sec\n",
    "epoch 1, iter 2520, avg. loss 16.31 total examples 100, speed 48359.54 words/sec, time elapsed 2563.93 sec\n",
    "epoch 1, iter 2530, avg. loss 17.18 total examples 100, speed 48289.49 words/sec, time elapsed 2566.05 sec\n",
    "epoch 1, iter 2540, avg. loss 16.71 total examples 100, speed 48341.47 words/sec, time elapsed 2568.17 sec\n",
    "epoch 1, iter 2550, avg. loss 16.59 total examples 100, speed 48026.95 words/sec, time elapsed 2570.30 sec\n",
    "epoch 1, iter 2560, avg. loss 17.72 total examples 100, speed 48327.28 words/sec, time elapsed 2572.42 sec\n",
    "epoch 1, iter 2570, avg. loss 16.40 total examples 100, speed 48347.58 words/sec, time elapsed 2574.54 sec\n",
    "epoch 1, iter 2580, avg. loss 17.65 total examples 100, speed 48305.89 words/sec, time elapsed 2576.66 sec\n",
    "epoch 1, iter 2590, avg. loss 16.79 total examples 100, speed 48254.62 words/sec, time elapsed 2578.78 sec\n",
    "epoch 1, iter 2600, avg. loss 16.83 total examples 100, speed 48356.95 words/sec, time elapsed 2580.90 sec\n",
    "VALIDATION: 2600 | Precision 0.0, recall 0.0, f1 0.0, accuracy: 0.8807943469785273\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=1024 --batch-size=10 --valid-niter=1000 --model=transformer --save-to=model.transformer.3.bin --transformer-depth=2 --transformer-heads=2 --cuda &\n",
    "\n",
    "[nohup.out.transformer.3]\n",
    "\n",
    "epoch 2, iter 4930, avg. loss 14.25 total examples 100, speed 89391.14 words/sec, time elapsed 770.42 sec\n",
    "epoch 2, iter 4940, avg. loss 14.62 total examples 100, speed 89258.57 words/sec, time elapsed 771.57 sec\n",
    "epoch 2, iter 4950, avg. loss 15.22 total examples 100, speed 89288.19 words/sec, time elapsed 772.72 sec\n",
    "epoch 2, iter 4960, avg. loss 14.39 total examples 100, speed 89393.78 words/sec, time elapsed 773.86 sec\n",
    "epoch 2, iter 4970, avg. loss 14.08 total examples 100, speed 89086.52 words/sec, time elapsed 775.01 sec\n",
    "epoch 2, iter 4980, avg. loss 14.42 total examples 100, speed 89506.94 words/sec, time elapsed 776.16 sec\n",
    "epoch 2, iter 4990, avg. loss 14.13 total examples 100, speed 89547.62 words/sec, time elapsed 777.30 sec\n",
    "epoch 2, iter 5000, avg. loss 12.94 total examples 100, speed 89079.11 words/sec, time elapsed 778.45 sec\n",
    "VALIDATION: 5000 | Precision 0.15478801169590642, recall 0.06501926146775876, f1 0.07690758334598957, accuracy: 0.8836647173488965\n",
    "save currently the best model to [model.transformer.3.bin]\n",
    "save model parameters to [model.transformer.3.bin]\n",
    "\n",
    "\n",
    "#### Test \n",
    "???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drcoding",
   "language": "python",
   "name": "drcoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
