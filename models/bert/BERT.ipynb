{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Commands\n",
    "\n",
    "### TOY\n",
    "#### Train \n",
    "python run.py train --train-src=../data_toy/train.data --dev-src=../data_toy/test.data --vocab=vocab.toy.json --target-length=256 --valid-niter=2 --model=bert --base-bert-path=../../biobert --log-every=1\n",
    "\n",
    "\n",
    "\n",
    "#### Test \n",
    "???\n",
    "\n",
    "\n",
    "\n",
    "### TINY\n",
    "#### Train \n",
    "python run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=512 --batch-size=4 --valid-niter=100 --base-bert-path=../../biobert --model=bert --log-every=1 --cuda --lr=0.00003\n",
    "\n",
    "#### Test \n",
    "python run.py predict model.bin ../data_v2/test.tiny.data ../predictions/bert.tiny.txt --target-length=512 --model=bert --log-every=10 --batch-size=4 --threshold=0.1 --base-bert-path=../../biobert --vocab=vocab.json --cuda\n",
    "\n",
    "\n",
    "### FULL\n",
    "#### Train \n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=512 --batch-size=4 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.bin --lr=0.00003 --cuda &\n",
    "\n",
    "Out of memory\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=512 --batch-size=2 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.bin --lr=0.00003 --cuda &\n",
    "\n",
    "out of memory\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.bin --lr=0.00003 --cuda &\n",
    "\n",
    "out of memory\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=128 --batch-size=2 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.bin --lr=0.00003 --cuda\n",
    "\n",
    "[nohup.out.bert]\n",
    "\n",
    "epoch 3, iter 48980, avg. loss 2.38 total examples 20, speed 1626.87 words/sec, time elapsed 13511.82 sec\n",
    "03/08/2020 22:49:39 - INFO - drcoding -   epoch 3, iter 48980, avg. loss 2.38 total examples 20, speed 1626.82 words/sec, time elapsed 13511.82 sec\n",
    "Loss is 0.21615931391716003\n",
    "Loss is 0.3235916793346405\n",
    "Loss is 0.23500174283981323\n",
    "Loss is 0.26939475536346436\n",
    "Loss is 0.3003152310848236\n",
    "Loss is 0.3832765817642212\n",
    "Loss is 0.3016652464866638\n",
    "Loss is 0.24877357482910156\n",
    "Loss is 0.25019487738609314\n",
    "Loss is 0.1936662644147873\n",
    "epoch 3, iter 48990, avg. loss 2.72 total examples 20, speed 1631.98 words/sec, time elapsed 13513.39 sec\n",
    "03/08/2020 22:49:41 - INFO - drcoding -   epoch 3, iter 48990, avg. loss 2.72 total examples 20, speed 1631.95 words/sec, time elapsed 13513.39 sec\n",
    "Loss is 0.206642284989357\n",
    "Loss is 0.3418208956718445\n",
    "Loss is 0.26975253224372864\n",
    "Loss is 0.23573069274425507\n",
    "Loss is 0.22950121760368347\n",
    "Loss is 0.1351146250963211\n",
    "Loss is 0.322563111782074\n",
    "Loss is 0.25348415970802307\n",
    "Loss is 0.3175578713417053\n",
    "Loss is 0.3516179621219635\n",
    "epoch 3, iter 49000, avg. loss 2.66 total examples 20, speed 1625.49 words/sec, time elapsed 13514.96 sec\n",
    "03/08/2020 22:49:43 - INFO - drcoding -   epoch 3, iter 49000, avg. loss 2.66 total examples 20, speed 1625.46 words/sec, time elapsed 13514.96 sec\n",
    "VALIDATION: 49000 | Precision 0.2856359649122807, recall 0.07309787248243994, f1 0.1080783890764448, accuracy: 0.8856359649122513\n",
    "03/08/2020 22:51:39 - INFO - drcoding -   VALIDATION: 49000 | Precision 0.2856359649122807, recall 0.07309787248243994, f1 0.1080783890764448, accuracy: 0.8856359649122513\n",
    "hit patience 5\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.2.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.2]\n",
    "\n",
    "VALIDATION: 75000 | Precision 0.5647417153996123, recall 0.5527231889314561, f1 0.5110219329645993, accuracy: 0.8937426900584575\n",
    "03/11/2020 16:50:09 - INFO - drcoding -   VALIDATION: 75000 | Precision 0.5647417153996123, recall 0.5527231889314561, f1 0.5110219329645993, accuracy: 0.8937426900584575\n",
    "save currently the best model to [model.bert.2.bin]\n",
    "03/11/2020 16:50:09 - INFO - drcoding -   save currently the best model to [model.bert.2.bin]\n",
    "save model parameters to [model.bert.2.bin]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.1000.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.3.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "TBD\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=512 --batch-size=1 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.4.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "TBD\n",
    "\n",
    "\n",
    "#### Test \n",
    "\n",
    "python -u run.py predict model.bert.bin ../data_v2/test.data ../predictions/bert.txt --vocab-test=vocab.json --target-length=128 --batch-size=2 --model=bert --log-every=1 --base-bert-path=../../biobert --cuda --threshold=0.1\n",
    "\n",
    "Precision 0.595270819118173, recall 0.25956516934853613, f1 0.314890219722594, accuracy: 0.8884803587093777\n",
    "03/08/2020 23:55:48 - INFO - drcoding -   Precision 0.595270819118173, recall 0.25956516934853613, f1 0.314890219722594, accuracy: 0.8884803587093777\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT with Metadata Commands\n",
    "\n",
    "### TOY\n",
    "#### Train \n",
    "python -u run.py train --train-src=../data_toy/train.data --dev-src=../data_toy/dev.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.7.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt\n",
    "\n",
    "\n",
    "\n",
    "#### Test \n",
    "???\n",
    "\n",
    "### TINY\n",
    "#### Train \n",
    "python -u run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.7.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt\n",
    "\n",
    "\n",
    "\n",
    "#### Test \n",
    "???\n",
    "\n",
    "\n",
    "### FULL\n",
    "#### Train \n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=128 --batch-size=2 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.bin --lr=0.00003 --threshold=0.1 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata]\n",
    "VALIDATION: 1000 | Precision 0.4010721247563353, recall 0.08028662471931527, f1 0.12715607284241892, accuracy: 0.8768372319687967\n",
    "03/09/2020 17:10:54 - INFO - drcoding -   VALIDATION: 1000 | Precision 0.4010721247563353, recall 0.08028662471931527, f1 0.12715607284241892, accuracy: 0.8768372319687967\n",
    "save currently the best model to [model.bert.metadata.bin]\n",
    "03/09/2020 17:10:54 - INFO - drcoding -   save currently the best model to [model.bert.metadata.bin]\n",
    "save model parameters to [model.bert.metadata.bin]\n",
    "\n",
    "epoch 1, iter 1010, avg. loss 3.85 total examples 20, speed 20.68 words/sec, time elapsed 289.07 sec\n",
    "03/09/2020 17:10:57 - INFO - drcoding -   epoch 1, iter 1010, avg. loss 3.85 total examples 20, speed 20.68 words/sec, time elapsed 289.07 sec\n",
    "Loss is 0.39699554443359375\n",
    "Loss is 0.4449789226055145\n",
    "Loss is 0.3943668305873871\n",
    "Loss is 0.39213454723358154\n",
    "Loss is 0.2089499980211258\n",
    "Loss is 0.3133094012737274\n",
    "Loss is 0.38358449935913086\n",
    "Loss is 0.31056150794029236\n",
    "Loss is 0.2178524136543274\n",
    "Loss is 0.5955561399459839\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=1 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.2.bin --lr=0.00003 --threshold=0.1 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.2]\n",
    "- Metadata was repeated multiple times\n",
    "- Performance was not very good\n",
    "\n",
    "VALIDATION: 2000 | Precision 0.4010721247563353, recall 0.08028662471931527, f1 0.12715607284241892, accuracy: 0.8768372319687967\n",
    "03/11/2020 05:17:54 - INFO - drcoding -   VALIDATION: 2000 | Precision 0.4010721247563353, recall 0.08028662471931527, f1 0.12715607284241892, accuracy: 0.8768372319687967\n",
    "save currently the best model to [model.bert.metadata.2.bin]\n",
    "03/11/2020 05:17:54 - INFO - drcoding -   save currently the best model to [model.bert.metadata.2.bin]\n",
    "save model parameters to [model.bert.metadata.2.bin]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.3.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.3a] <- prematurel\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=16 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.4.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[peak GPU memory 6673MiB]\n",
    "[nohup.out.bert.metadata.4]\n",
    "\n",
    "VALIDATION: 9000 | Precision 0.46115984405457744, recall 0.45607287846073014, f1 0.4189164854521403, accuracy: 0.8730263157894635\n",
    "03/11/2020 21:18:24 - INFO - drcoding -   VALIDATION: 9000 | Precision 0.46115984405457744, recall 0.45607287846073014, f1 0.4189164854521403, accuracy: 0.8730263157894635\n",
    "save currently the best model to [model.bert.metadata.4.bin]\n",
    "03/11/2020 21:18:24 - INFO - drcoding -   save currently the best model to [model.bert.metadata.4.bin]\n",
    "save model parameters to [model.bert.metadata.4.bin]\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=512 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.5.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.5]\n",
    "\n",
    "VALIDATION: 11000 | Precision 0.4632309941520442, recall 0.4538659134822584, f1 0.4186755737111231, accuracy: 0.8734405458089566\n",
    "03/12/2020 02:45:31 - INFO - drcoding -   VALIDATION: 11000 | Precision 0.4632309941520442, recall 0.4538659134822584, f1 0.4186755737111231, accuracy: 0.8734405458089566\n",
    "save currently the best model to [model.bert.metadata.5.bin]\n",
    "03/12/2020 02:45:31 - INFO - drcoding -   save currently the best model to [model.bert.metadata.5.bin]\n",
    "save model parameters to [model.bert.metadata.5.bin]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=1024 --batch-size=4 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.6.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "[nohup.out.bert.metadata.6]\n",
    "\n",
    "- Terminated early due to errors in the validation\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=2048 --batch-size=2 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.7.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda &\n",
    "[nohup.out.bert.metadata.7]\n",
    "- Surprisingly bad performance, most likely due to disabling the positional embeddings\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "python -u run.py predict model.bert.metadata.2.bin ../data_v2/dev.tiny.data ../predictions/bert.metadata.txt --vocab-test=vocab.json --target-length=256 --batch-size=1 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --top-k=5 --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt\n",
    "\n",
    "- Tried predicting each of the 50 classes independently. This was really slow and resulted in poor performance overall. Abandoning approach.  \n",
    "Completed 100/100\n",
    "  SO FAR: Precision 0.2719999999999998, recall 0.2519441669441668, f1 0.24114677502293597, accuracy: 0.8446000000000002\n",
    "Precision 0.2719999999999998, recall 0.2519441669441668, f1 0.24114677502293597, accuracy: 0.8446000000000002\n",
    "\n",
    "---\n",
    "\n",
    "nohup python run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.data --vocab=vocab.json --target-length=256 --batch-size=16 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.9.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.9]\n",
    "- This version uses additional layers and a tanh, but doesn't seem to have a good \n",
    "\n",
    "ll 0.42817351744591886, f1 0.3938878307458599, accuracy: 0.8680701754385891\n",
    "03/13/2020 03:57:28 - INFO - drcoding -   VALIDATION: 9000 | Precision 0.43637914230019226, recall 0.42817351744591886, f1 0.3938878307458599, accuracy: 0.8680701754385891\n",
    "save currently the best model to [model.bert.metadata.9.bin]\n",
    "03/13/2020 03:57:28 - INFO - drcoding -   save currently the best model to [model.bert.metadata.9.bin]\n",
    "save model parameters to [model.bert.metadata.9.bin]\n",
    "\n",
    "\n",
    "#### Test \n",
    "\n",
    "python -u run.py predict model.bert.metadata.4.bin ../data_v2/dev.tiny.5.data ../predictions/bert.metadata.2.txt --vocab-test=vocab.json --target-length=256 --batch-size=1 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --top-k=5 --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "python run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=10 --model=bert --base-bert-path=../../biobert --save-to=model.bert.metadata.9.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt --cuda\n",
    "\n",
    "python run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=10 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.9.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --d-icd-file=../data/D_ICD_DIAGNOSES.csv --top-icd-file=../data_v2/icd.txt --cuda\n",
    "\n",
    "\n",
    "## Batch Size Test (normal vs metadata)\n",
    "\n",
    "python -u run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=512 --batch-size=6 --valid-niter=100 --model=bert --base-bert-path=../../biobert --save-to=model.bert.3.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda\n",
    "- 8 is out of memory\n",
    "- 6 is barely enough (~8gb)\n",
    "\n",
    "\n",
    "python -u run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=512 --batch-size=6 --valid-niter=2 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.4.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda\n",
    "- 6 is enough (~5.6gb)\n",
    "\n",
    "\n",
    "\n",
    "python -u run.py train --train-src=../data_v2/train.tiny.data --dev-src=../data_v2/dev.tiny.data --vocab=vocab.json --target-length=64 --batch-size=2 --valid-niter=2 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.4.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt\n",
    "\n",
    "\n",
    "python -u run.py predict model.bert.metadata.5.bin ../data_v2/test.data ../predictions/bert.test.txt --vocab-test=vocab.json --target-length=1024 --batch-size=1 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --cuda --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V3\n",
    "\n",
    "\n",
    "nohup python run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.data --vocab=vocab.json --target-length=512 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.1.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.v3.1]\n",
    "\n",
    "- Stopped early, learning was too slow\n",
    "VALIDATION: 10000 | Precision 0.3558830146231659, recall 0.41352755902342103, f1 0.3493093294312918, accuracy: 0.8749831271090956\n",
    "03/13/2020 16:44:37 - INFO - drcoding -   VALIDATION: 10000 | Precision 0.3558830146231659, recall 0.41352755902342103, f1 0.3493093294312918, accuracy: 0.8749831271090956\n",
    "save currently the best model to [model.bert.metadata.v3.1.bin]\n",
    "03/13/2020 16:44:37 - INFO - drcoding -   save currently the best model to [model.bert.metadata.v3.1.bin]\n",
    "save model parameters to [model.bert.metadata.v3.1.bin]\n",
    "\n",
    "\n",
    "python -u run.py train --train-src=../data_v3/train.tiny.data --dev-src=../data_v3/dev.tiny.data --vocab=vocab.v3.json --target-length=512 --batch-size=8 --valid-niter=100 --model=bert-metadata --base-bert-path=../../biobert --save-to=test.bin --lr=0.0003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda\n",
    "\n",
    "python -u run.py predict test.bin ../data_v3/train.tiny.data ../predictions/custom.txt --vocab-test=vocab.v3.json --target-length=512 --batch-size=8 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --top-k=4\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.data --vocab=vocab.json --target-length=512 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.2.bin --lr=0.0003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda &\n",
    "\n",
    "- WRONG vocab\n",
    "- Increase learning by a factor of 10\n",
    "- Try with new sub-batch masking logic\n",
    "\n",
    "[nohup.out.bert.metadata.v3.2]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.tiny.data --dev-src=../data_v3/dev.tiny.data --vocab=vocab.v3.json --target-length=500 --batch-size=8 --valid-niter=10 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.3.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda &\n",
    "\n",
    "[nohup.out.bert.metadata.v3.3]\n",
    "\n",
    "VALIDATION: 12000 | Precision 0.3591999999999984, recall 0.42151542232277506, f1 0.3552502173351256, accuracy: 0.8769599999999984\n",
    "03/14/2020 05:49:06 - INFO - drcoding -   VALIDATION: 12000 | Precision 0.3591999999999984, recall 0.42151542232277506, f1 0.3552502173351256, accuracy: 0.8769599999999984\n",
    "save currently the best model to [model.bert.metadata.v3.3.bin]\n",
    "03/14/2020 05:49:06 - INFO - drcoding -   save currently the best model to [model.bert.metadata.v3.3.bin]\n",
    "save model parameters to [model.bert.metadata.v3.3.bin]\n",
    "\n",
    "python -u run.py predict model.bert.metadata.v3.3.bin ../data_v3/dev.1000.data ../predictions/bert.metadata.v3.3.txt --vocab-test=vocab.v3.json --target-length=500 --batch-size=10 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --cuda --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --meta-len=250\n",
    "[^ uses the full attention with original text]\n",
    "Completed 1000/1000\n",
    "  SO FAR: Precision 0.3591999999999984, recall 0.42151542232277506, f1 0.3552502173351256, accuracy: 0.8769599999999984\n",
    "Precision 0.3591999999999984, recall 0.42151542232277506, f1 0.3552502173351256, accuracy: 0.8769599999999984\n",
    "03/14/2020 17:33:19 - INFO - drcoding -   Precision 0.3591999999999984, recall 0.42151542232277506, f1 0.3552502173351256, accuracy: 0.8769599999999984\n",
    "\n",
    "\n",
    "python -u run.py predict model.bert.metadata.v3.3.bin ../data_v3/dev.1000.data ../predictions/bert.metadata.v3.3-full-meta.txt --vocab-test=vocab.v3.json --target-length=500 --batch-size=16 --model=bert-metadata --log-every=1 --base-bert-path=../../biobert --cuda --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --meta-len=250\n",
    "[^ uses attention with concat metadata]\n",
    "\n",
    "  SO FAR: Precision 0.36859999999999804, recall 0.4295944988018517, f1 0.3642109705911572, accuracy: 0.8788399999999983\n",
    "Precision 0.36859999999999804, recall 0.4295944988018517, f1 0.3642109705911572, accuracy: 0.8788399999999983\n",
    "03/14/2020 17:24:59 - INFO - drcoding -   Precision 0.36859999999999804, recall 0.4295944988018517, f1 0.3642109705911572, accuracy: 0.8788399999999983\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=256 --batch-size=16 --valid-niter=1000 --model=bert --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.4.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda &\n",
    "\n",
    "VALIDATION: 13000 | Precision 0.43139999999999834, recall 0.510167546995488, f1 0.4276897265101609, accuracy: 0.8913999999999983\n",
    "I0314 06:11:40.763740 140502334007040 run.py:439] VALIDATION: 13000 | Precision 0.43139999999999834, recall 0.510167546995488, f1 0.4276897265101609, accuracy: 0.8913999999999983\n",
    "save currently the best model to [model.bert.metadata.v3.4.bin]\n",
    "I0314 06:11:40.763967 140502334007040 run.py:447] save currently the best model to [model.bert.metadata.v3.4.bin]\n",
    "save model parameters to [model.bert.metadata.v3.4.bin]\n",
    "\n",
    "[nohup.out.bert.v3.4]\n",
    "\n",
    "python -u run.py predict model.bert.metadata.v3.4.bin ../data_v3/dev.data ../predictions/bert.v3.4.txt --vocab-test=vocab.v3.json --target-length=256 --batch-size=16 --model=bert --log-every=1 --base-bert-path=../../biobert --cuda --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt\n",
    "\n",
    "- Original BERT model\n",
    "\n",
    "\n",
    "predict model.bert.metadata.8.bin ../data_v3/dev.data ../predictions/bert.v3.4.txt --vocab-test=vocab.v3.json --target-length=256 --batch-size=16 --model=bert --log-every=1 --base-bert-path=../../biobert --cuda --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=475 --batch-size=5 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.5.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=475 &\n",
    "- trying with full concatenated metadata descriptions all the time\n",
    "- Fixed metadata lengths are garbage, does not train. does not improve.\n",
    "[nohup.out.bert.metadata.v3.5]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=475 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.6.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=95 &\n",
    "- try self attention in smaller chunks and averaging across smaller chunks\n",
    "- slow learning, but sorta learns\n",
    "[nohup.out.bert.metadata.v3.6]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=475 --batch-size=2 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.7.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=475 &\n",
    "- adding a little metadata in full self attention\n",
    "- not good\n",
    "\n",
    "[nohup.out.bert.metadata.v3.7]\n",
    "\n",
    "VALIDATION: 4000 | Precision 0.27979999999999866, recall 0.2977661957323721, f1 0.26934851515873237, accuracy: 0.8610800000000004\n",
    "I0314 22:20:51.489220 139823918421760 run.py:458] VALIDATION: 4000 | Precision 0.27979999999999866, recall 0.2977661957323721, f1 0.26934851515873237, accuracy: 0.8610800000000004\n",
    "save currently the best model to [model.bert.metadata.v3.7.bin]\n",
    "I0314 22:20:51.489452 139823918421760 run.py:466] save currently the best model to [model.bert.metadata.v3.7.bin]\n",
    "save model parameters to [model.bert.metadata.v3.7.bin]\n",
    "\n",
    "\n",
    "===\n",
    "\n",
    "- Found bug where the BERT embedding for the metadata was constantly being created as zero :(\n",
    "- Tryhing some old experiments again\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=512 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.8.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=32 &\n",
    "\n",
    "VALIDATION: 2000 | Precision 0.2187999999999992, recall 0.25117677877677863, f1 0.21629993359753477, accuracy: 0.8488800000000009\n",
    "I0315 05:08:17.556517 140027617675008 run.py:459] VALIDATION: 2000 | Precision 0.2187999999999992, recall 0.25117677877677863, f1 0.21629993359753477, accuracy: 0.8488800000000009\n",
    "hit patience 1\n",
    "I0315 05:08:17.556758 140027617675008 run.py:475] hit patience 1\n",
    "Saving latest model...\n",
    "save model parameters to [model.bert.metadata.v3.8.bin.latest]\n",
    "\n",
    "- immediately overfits\n",
    "[nohup.out.bert.metadata.v3.8]\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=475 --batch-size=1 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.9.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=475 &\n",
    "\n",
    "- this version uses the full metadata \n",
    "[nohup.out.bert.metadata.v3.9]\n",
    "\n",
    "- too slow\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=475 --batch-size=1 --valid-niter=10000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.10.bin --lr=0.0001 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=475 &\n",
    "- performance does not exceed \n",
    "\n",
    "VALIDATION: 140000 | Precision 0.27979999999999866, recall 0.2977661957323721, f1 0.26934851515873237, accuracy: 0.8610800000000004\n",
    "I0315 16:41:35.114703 140698947761920 run.py:471] VALIDATION: 140000 | Precision 0.27979999999999866, recall 0.2977661957323721, f1 0.26934851515873237, accuracy: 0.8610800000000004\n",
    "hit patience 5\n",
    "I0315 16:41:35.114962 140698947761920 run.py:487] hit patience 5\n",
    "Saving latest model...\n",
    "save model parameters to [model.bert.metadata.v3.10.bin.latest]\n",
    "\n",
    "[nohup.out.bert.metadata.v3.10]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v3/train.data --dev-src=../data_v3/dev.1000.data --vocab=vocab.v3.json --target-length=512 --batch-size=8 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.11.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v3/icd-desc.processed.txt --cuda --meta-len=32 &\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "nohup python -u run.py train --train-src=../data_v2/train.data --dev-src=../data_v2/dev.1000.data --vocab=vocab.json --target-length=256 --batch-size=2 --valid-niter=1000 --model=bert-metadata --base-bert-path=../../biobert --save-to=model.bert.metadata.v3.12.bin --lr=0.00003 --top-k=5 --icd-desc-file=../data_v2/icd-desc.processed.txt --cuda --meta-len=32 &\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drcoding",
   "language": "python",
   "name": "drcoding"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
